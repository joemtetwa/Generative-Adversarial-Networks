{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Frechet_Inception_Distance.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-1opPclODF3_"
      },
      "outputs": [],
      "source": [
        "# Measuring GAN using Frechet Inception Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F4XKf1UpEuMQ"
      },
      "outputs": [],
      "source": [
        "## Outline\n",
        "- Introduction\n",
        "- Load Model\n",
        "    - Download Model\n",
        "    - Init Model\n",
        "- Generate Images\n",
        "- Measuring Frechet Inception Distance\n",
        "    1. Generate fake samples and (get) real samples\n",
        "    2. Measure mean ($\\mu$) and covariance ($\\Sigma$) of each samples\n",
        "    3. Calculate Frechet distance using the means and covariances\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RHAn6sqXEuMR"
      },
      "outputs": [],
      "source": [
        "## Introduction\n",
        "\n",
        "Frechet Inception Distance is a proposed evaluation method as an improvisation of Inception score. By using the same neural network as Inception score, Frechet Inception Distance measures the features extracted from real samples (usually come from real data sample) and fake samples (generated by model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "CGnaZlSNEuMS",
        "outputId": "f72dd63d-2c0c-4bc6-a949-e3251754b887"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "## Folder Configuration\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "ROOT = \"/content/drive/My Drive/Colab Notebooks/DSC_UI_GAN/Batch1/W3/\"\n",
        "\n",
        "# Make dir if no exist\n",
        "if not os.path.exists(ROOT):\n",
        "    os.makedirs(ROOT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xoTsNEWXEuMV"
      },
      "outputs": [],
      "source": [
        "## Load Model\n",
        "\n",
        "We will use DCGAN model implemented in [Pytorch](https://github.com/pytorch/examples/tree/master/dcgan), with trained weights provided by [csinva/gan-pretrained-pytorch](https://github.com/csinva/gan-pretrained-pytorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gelfqLCxEuMW"
      },
      "outputs": [],
      "source": [
        "### Download weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "i36bkSpDHdWK",
        "outputId": "01d84f61-e2d9-4887-f9f3-7e75f297532c"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "wget https://github.com/DSC-UI-SRIN/Introduction-to-GAN/raw/master/3%20-%20GAN%20Evaluations/weight/netD_epoch_199.pth -d netD_epoch_199.pth\n",
        "wget https://github.com/DSC-UI-SRIN/Introduction-to-GAN/raw/master/3%20-%20GAN%20Evaluations/weight/netG_epoch_199.pth -d netG_epoch_199.pth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EHG6VVBqB9cK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QqjeSgYMDDxA"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu, nc=3, nz=100, ngf=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(    ngf,      nc, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Qgk9FXn0DQYa"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu, nc=3, ndf=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 2, 2, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "\n",
        "        return output.view(-1, 1).squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Siy0Me_VB9cZ"
      },
      "outputs": [],
      "source": [
        "num_gpu = 1 if torch.cuda.is_available() else 0\n",
        "\n",
        "D = Discriminator(ngpu=1).eval()\n",
        "G = Generator(ngpu=1).eval()\n",
        "\n",
        "# load weights\n",
        "D.load_state_dict(torch.load(\"./netD_epoch_199.pth\"))\n",
        "G.load_state_dict(torch.load(\"./netG_epoch_199.pth\"))\n",
        "if torch.cuda.is_available():\n",
        "    D = D.cuda()\n",
        "    G = G.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cjr0IszKB9cf"
      },
      "outputs": [],
      "source": [
        "## Generate samples from model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "colab_type": "code",
        "id": "n7I0SJRNB9ch",
        "outputId": "15722a72-8db6-4c41-f81d-c60c95ed34ce"
      },
      "outputs": [],
      "source": [
        "batch_size = 25\n",
        "latent_size = 100\n",
        "\n",
        "fixed_noise = torch.randn(batch_size, latent_size, 1, 1)\n",
        "if torch.cuda.is_available():\n",
        "    fixed_noise = fixed_noise.cuda()\n",
        "fake_images = G(fixed_noise)\n",
        "\n",
        "fake_images_np = fake_images.cpu().detach().numpy()\n",
        "fake_images_np = fake_images_np.reshape(fake_images_np.shape[0], 3, 32, 32)\n",
        "fake_images_np = fake_images_np.transpose((0, 2, 3, 1))\n",
        "R, C = 5, 5\n",
        "\n",
        "for i in range(batch_size):\n",
        "    plt.subplot(R, C, i + 1)\n",
        "    plt.imshow(fake_images_np[i] * 0.5 + 0.5, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.savefig(ROOT + \"dcgan_sample.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oXH8buY0B9cu"
      },
      "outputs": [],
      "source": [
        "## Measure FID on model\n",
        "\n",
        "FID implementation by [mseitzer](https://github.com/mseitzer/pytorch-fid)\n",
        "\n",
        "### 1. Generate fake samples and get real data samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "AZiR-NzjEuMo",
        "outputId": "54603f3d-07c9-43af-f216-699521f98ca2"
      },
      "outputs": [],
      "source": [
        "%%bash \n",
        "\n",
        "wget https://github.com/mseitzer/pytorch-fid/raw/master/inception.py -d inception.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2HaeH_pXH2TW"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import adaptive_avg_pool2d\n",
        "\n",
        "from inception import InceptionV3\n",
        "\n",
        "from scipy import linalg\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "colab_type": "code",
        "id": "pVRQRSxeB9cy",
        "outputId": "2cdd3a93-d40c-403e-9fad-bb18269564ae"
      },
      "outputs": [],
      "source": [
        "n_samples = 1000\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "cifar10 = datasets.CIFAR10('./data', transform=transform, download=True)\n",
        "cifar10_loader = DataLoader(cifar10, batch_size=n_samples, shuffle=True)\n",
        "cifar10_iter = iter(cifar10_loader)\n",
        "\n",
        "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "doO2393YN7DP",
        "outputId": "b564e43d-105e-4316-941d-e7b1e43433f5"
      },
      "outputs": [],
      "source": [
        "real_samples, _ = cifar10_iter.next()\n",
        "real_samples.shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "TgiXcG5QJCJ-",
        "outputId": "2357634b-3f2c-4bbd-ef2a-861890bb28ac"
      },
      "outputs": [],
      "source": [
        "fixed_noise = torch.randn(n_samples, latent_size, 1, 1)\n",
        "if torch.cuda.is_available():\n",
        "    fixed_noise = fixed_noise.cuda()\n",
        "fake_images = G(fixed_noise)\n",
        "fake_images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hWGhBoCRKxYg"
      },
      "outputs": [],
      "source": [
        "### 2. Calculate mean and covariance of Inception activations on each samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WFhgqX2OLehF"
      },
      "outputs": [],
      "source": [
        "def get_activations(files, model, batch_size=50, dims=2048, cuda=False):\n",
        "    \"\"\"Calculates the activations of the pool_3 layer for all images.\n",
        "    Params:\n",
        "    -- files       : List of images data\n",
        "    -- model       : Instance of inception model\n",
        "    -- batch_size  : Batch size of images for the model to process at once.\n",
        "    -- dims        : Dimensionality of features returned by Inception\n",
        "    -- cuda        : If set to True, use GPU\n",
        "    Returns:\n",
        "    -- A numpy array of dimension (num images, dims) that contains the\n",
        "       activations of the given tensor when feeding inception with the\n",
        "       query tensor.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    if batch_size > len(files):\n",
        "        print(('Warning: batch size is bigger than the data size. '\n",
        "               'Setting batch size to data size'))\n",
        "        batch_size = len(files)\n",
        "\n",
        "    n_batches = len(files) // batch_size\n",
        "    n_used_imgs = n_batches * batch_size\n",
        "\n",
        "    pred_arr = np.empty((n_used_imgs, dims))\n",
        "\n",
        "    for i in tqdm(range(n_batches)):\n",
        "        print('\\rPropagating batch %d/%d' % (i + 1, n_batches), end='', flush=True)\n",
        "        start = i * batch_size\n",
        "        end = start + batch_size\n",
        "\n",
        "        images = files[start:end]\n",
        "\n",
        "        # batch = torch.from_numpy(images).type(torch.FloatTensor)\n",
        "        if cuda:\n",
        "            # batch = batch.cuda()\n",
        "            batch = images.cuda()\n",
        "\n",
        "        pred = model(batch)[0]\n",
        "\n",
        "        # If model output is not scalar, apply global spatial average pooling.\n",
        "        # This happens if you choose a dimensionality not equal 2048.\n",
        "        if pred.shape[2] != 1 or pred.shape[3] != 1:\n",
        "            pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
        "\n",
        "        pred_arr[start:end] = pred.cpu().data.numpy().reshape(batch_size, -1)\n",
        "\n",
        "    print(' done')\n",
        "\n",
        "    return pred_arr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "W7OTh8ndKxGB"
      },
      "outputs": [],
      "source": [
        "def calculate_activation_statistics(files, model, batch_size=50, dims=2048, cuda=False, verbose=False):\n",
        "    \"\"\"Calculation of the statistics used by the FID.\n",
        "    Params:\n",
        "    -- files       : List of image files paths\n",
        "    -- model       : Instance of inception model\n",
        "    -- batch_size  : Size of batch per processing in Inception modl\n",
        "    -- dims        : Dimensionality of features returned by Inception\n",
        "    -- cuda        : If set to True, use GPU\n",
        "    -- verbose     : If set to True and parameter out_step is given, the\n",
        "                     number of calculated batches is reported.\n",
        "    Returns:\n",
        "    -- mu    : The mean over samples of the activations of the pool_3 layer of\n",
        "               the inception model.\n",
        "    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n",
        "               the inception model.\n",
        "    \"\"\"\n",
        "    act = get_activations(files, model, batch_size, dims, cuda)\n",
        "    mu = np.mean(act, axis=0)\n",
        "    sigma = np.cov(act, rowvar=False)\n",
        "    \n",
        "    return mu, sigma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "colab_type": "code",
        "id": "sQDViPmLX1Tw",
        "outputId": "39e5c2c4-b2ff-4cea-ccb4-bffa600b8cc0"
      },
      "outputs": [],
      "source": [
        "dims = 2048\n",
        "batch_size = 50\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
        "\n",
        "model = InceptionV3([block_idx], normalize_input=False)\n",
        "if cuda:\n",
        "    model.cuda()\n",
        "\n",
        "m_real, sigma_real = calculate_activation_statistics(real_samples, model, batch_size, dims, cuda)\n",
        "m_fake, sigma_fake = calculate_activation_statistics(fake_images, model, batch_size, dims, cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1j5AmvpZZQ9R"
      },
      "outputs": [],
      "source": [
        "## Measure Frechet distance given the means and covariances\n",
        "\n",
        "According to the [paper](https://arxiv.org/pdf/1706.08500.pdf)\n",
        "\n",
        "![Excerpt from paper](https://i.stack.imgur.com/9gUDE.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zmzfTLV8YsXH"
      },
      "outputs": [],
      "source": [
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
        "    \"\"\"Numpy implementation of the Frechet Distance. Stable version by Dougal J. Sutherland.\n",
        "    Params:\n",
        "    -- mu1   : The sample mean over activations, precalculated on an generative data set.\n",
        "    -- mu2   : The sample mean over activations, precalculated on a representative data set.\n",
        "    -- sigma1: The covariance matrix over activations for generated samples.\n",
        "    -- sigma2: The covariance matrix over activations, precalculated on a representative data set.\n",
        "    Returns:\n",
        "    -- The Frechet distance calculated\n",
        "    \"\"\"\n",
        "    # Check dimension of mu and sigma \n",
        "    mu1 = np.atleast_1d(mu1)\n",
        "    mu2 = np.atleast_1d(mu2)\n",
        "\n",
        "    sigma1 = np.atleast_2d(sigma1)\n",
        "    sigma2 = np.atleast_2d(sigma2)\n",
        "\n",
        "    assert mu1.shape == mu2.shape, 'Training and test mean vectors have different lengths'\n",
        "    assert sigma1.shape == sigma2.shape, 'Training and test covariances have different dimensions'\n",
        "\n",
        "    # Calculate mu_1 - mu_2\n",
        "    diff = mu1 - mu2\n",
        "\n",
        "    # Calculate square root mean of sigma_1 * sigma_2\n",
        "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "\n",
        "    # Product might be almost singular\n",
        "    if not np.isfinite(covmean).all():\n",
        "        msg = ('fid calculation produces singular product; '\n",
        "               'adding %s to diagonal of cov estimates') % eps\n",
        "        print(msg)\n",
        "        offset = np.eye(sigma1.shape[0]) * eps\n",
        "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
        "\n",
        "    # Numerical error might give slight imaginary component\n",
        "    if np.iscomplexobj(covmean):\n",
        "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "            m = np.max(np.abs(covmean.imag))\n",
        "            raise ValueError('Imaginary component {}'.format(m))\n",
        "        covmean = covmean.real\n",
        "\n",
        "    # Get trace of covmean\n",
        "    tr_covmean = np.trace(covmean)\n",
        "\n",
        "    # Return the calculated FID result\n",
        "    return (diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "YYZXWeDmZBJk",
        "outputId": "4a3abc06-f6a4-4b6b-ef36-4c210bd742b0"
      },
      "outputs": [],
      "source": [
        "fid_value = calculate_frechet_distance(m_real, sigma_real, m_fake, sigma_fake)\n",
        "\n",
        "print('FID score of model: {:3.5f}'.format(fid_value))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5h3JcFNcZzBr"
      },
      "outputs": [],
      "source": []
    }
  ]
}